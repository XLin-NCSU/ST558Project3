---
title: "Project 3"
output: github_document
author: Xi Lin, Sarat Bantupalli
params: 
  Education: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE)
```

### This report is for Education level `r params$Education`.

## Required Packages

```{r packages, echo=FALSE}
library(tidyverse)
library(corrplot)
library(caret)
```


## Introduction
This project creates predictive models using available data and automates R Markdown reports. We demonstrated it by using [Diabates Health Indicators Data](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset) collected by the Centers of Disease Control and Prevention (CDC).  

The data was collected through a telephonic survey by the CDC in the year 2015 and it corresponds to the prevalence of diabetes in the survey respondents. The data set we analyzed here represents responses from 253,680 Americans on health-related risk behaviors, chronic health conditions, and the use of preventative services. The data set itself is *not balanced*.  

### Model Variables
The response variable of interest from the data set is *Diabetes_binary*. It represents if the survey respondent is *non diabetic (value 0)* or *pre-diabetic/ diabetic (value 1)*.

The explanatory variables were chosen such that important risk factors for diabetes including health & lifestyle, socioeconomic status, and demographics (age and sex) are considered in the predictive model. We included the following explanatory variables for the model:  

+ *HighBP*: This variable represents if a respondent was diagnosed with high blood pressure (value 1) or not (value 0). Research indicates high blood pressure is twice as likely to strike a person with diabetes than a person without diabetes  
+ *HighChol*: This variable represents if a respondent has high cholesterol (value 1) or not (value 0). Research suggests people with diabetes tend to have higher cholesterol levels  
+ *BMI*: The body mass index, a numerical variable, is a good indicator for obesity and represents the overall health of a person making it an ideal candidate for the model  
+ *Smoker*: Smoking increases the risk of diabetes and hence was included in the model. This variable can take two values, 0- did not smoke 100 cigarettes in lifetime or 1- smoked more than 100 cigarettes in lifetime  
+ *PhysicalActivity*: This variable indicates if the respondent had been physically active in the past 30 days. A value 0 represents no while 1 represents yes  
+ *Fruits*: A healthy diet is key to reducing the risk of type 2 diabetes and can represent lifestyle and socioeconomic status of the respondent. This variable indicates if the person is eating healthy or not. A value of 0 indicates no fruit consumed per day while 1 indicates some fruit consumed per day  
+ *Veggies*: This variable indicates if the person is eating healthy or not. It can represent lifestyle and socioeconomic status of the respondent. A value of 0 indicates no veggies consumed per day while 1 indicates some veggies consumed per day  
+ *HvyAlcoholConsump*: Alcohol increases the risk of diabetes and this variable encapsulates if the respondent is a heavy drinker  
+ *AnyHealthcare*: This variable represents socioeconomic status of the respondent, with low-income respondents not having any health coverage (value 0) while higher income respondents having some type of health coverage (value 1)  
+ *GenHlth*: This represents the overall health of the respondent ranging from 1 through 5 with 1 being the best health indicator  
+ *MentHlth*: This numerical variable represents days of poor mental health (1-30 days). People with mental health are 2 to 3 times more likely to have a depression than people without diabetes. This variable captures the overall health of the respondent  
+ *PhysHlth*: This numerical variable indicates physical illness or injury days in the past 30 days. Illness or injury can impact physical activity which in turn could affect diabetes risk  
+ *Sex*: Including the sex of the respondent (0- female, 1- male) could help us see if risk factors are different for men and women  
+ *Age*: Risk for type 2 diabetes increases with age. This 13 level categorical variable encapsulates this risk  
+ *Education*: Education might effect the socioeconomic status of a person and change the risk factor for diabetes. This variable was used to automate the R Markdown reports. Each report represents analysis for each level of this variable. A value of 2 indicates the respondent attended elementary school or less while 6 represents a college graduate  
+ *Income*: This categorical variable can affect factors that influence the risk for type 2 diabetes including access to health care, physical activity (eg. gym), and a healthy lifestyle. A value of 1 indicates low income (earning less than \$10,000), and a value of 8 indicates high income (>$75,000)  

### Purpose of EDA and Modeling
We used this project to develop predictive models for diabetes risk. With over 110 million Americans who are either diabetic or pre-diabetic, predictive models such as this can be of immense help for public health officials. We looked at how health & lifestyle, socioeconomic status, and demographics can help us predict the risk of diabetes for a person living in the United States. We have used the power of R Markdown to automate the report generation process based on the *Education* level of the person.  

Exploratory data analysis was the first step of this predictive modeling project. Although the variable selection process was based on knowledge of the field and metadata of the data set, EDA played an important role. EDA helped us visualize the data, looks for trends, and see correlation between variables.  


## Data Processing
The data for the analysis was read in using the `read_csv` function from the `readr` package and stored in the R object, *diabetes_data*. Then for the variable *Education*, groups 1 and 2 were combined into *group 2*. This was done to have five distinct groups for this variable ranging from 2 through 6.  

Then the response variable and some of the explanatory variables we are interested in were converted to factors. Explanatory variables that were converted to factors with meaningful level names include *HighBP*, *HighChol*, *Smoker*, *PhysicalActivity*, *Fruits*, *Veggies*, *HvyAlcoholConsump*, *AnyHealthcare*, *GenHlth*, *Sex*, *Age*, and *Income*.  

The data was then subset to represent different *Education* levels of the respondents in the survey.

```{r data_processing}
#Read in data using the read_csv function from readr package
diabetes_data <- read_csv("diabetes_binary_health_indicators_BRFSS2015.csv")

#Combine groups 1 and 2 into group 2 for Education variable
diabetes_data <- diabetes_data %>% 
  mutate(Education = if_else(Education == 1, 2, Education) %>% as.factor())

# Re-name the Diabetes_binary variable to a more meaningful description
diabetes_data$Diabetes_binary <- if_else(diabetes_data$Diabetes_binary == 0, 
                                    "No_Diabetes","Diabetes")

# Create a vector with the columns we want to convert to factors
columns_to_factor <- c("Diabetes_binary",
                       "HighBP",
                       "HighChol",
                       "Smoker",
                       "PhysActivity",
                       "Fruits",
                       "Veggies",
                       "HvyAlcoholConsump",
                       "AnyHealthcare",
                       "GenHlth",
                       "Sex",
                       "Age",
                       "Income")

# Change the columns we are interested in to a factor using the lapply function
diabetes_data[, columns_to_factor] <- lapply(diabetes_data[, columns_to_factor], factor)

# Subset the data to work on the Education level of interest
#Diabetes_Edu <- subset(diabetes, Education == params$Education)
diabetes_education_level <- subset(diabetes_data, Education == params$Education) %>% 
  select(-Education)
```

## Summarizations and Exploratory Data Analysis (EDA)
Here Exploratory Data Analysis on the full data (for the particular education level) was performed to look at trends in data, and correlations between variables.

### Summary Tables
The full data set was summarized into several tables as part of the EDA. The tables give summarize the information in the data. We looked at how health, socioeconomic status, and demographics affect diabetes_status.  

Using the `summary` function to look at the data points for Education level `r params$Education`.
```{r}
# Check for the balance of data 
summary(diabetes_education_level$Diabetes_binary)
```
The reader should notice if the data is balanced or not balanced for the response variable.  

Here the summary statistics of diabetes_status with respect to *BMI* were found using the `group_by()` function. BMI is a good indicator for obesity and represents the overall health of a person.

```{r}
# Summary BMI for diabetes vs non-diabetes respondents in the survey
diabetes_education_level %>% group_by(Diabetes_binary) %>% 
  summarise(avg = mean(BMI), sd = sd(BMI),
            min = min(BMI), max = max(BMI))

```

The reader should look for the average value of *BMI* for each setting of diabetes_status. On average, a lower value of BMI is expected for people without diabetes when compared to people with diabetes.  

Here the summary statistics of diabetes_status with respect to *Mental Health* were found. It captures the overall health of a person.

```{r}
# Summary Mental Health for diabetes vs non-diabetes respondents in the survey
diabetes_education_level %>% group_by(Diabetes_binary) %>% 
  summarise(avg = mean(MentHlth), sd = sd(MentHlth),
            min = min(MentHlth), max = max(MentHlth))

```
A low number of poor mental health days on average is expected for people with no diabetes while the contrary for people with diabetes.  

Here the summary statistics of diabetes_status with respect to *Physical Health* were found. It captures the health aspect of a person.
Illness or injury can impact physical activity which in turn could affect diabetes risk.

```{r}
# Summary Physical Health for diabetes vs non-diabetes respondents in the survey
diabetes_education_level %>% group_by(Diabetes_binary) %>% 
  summarise(avg = mean(PhysHlth), sd = sd(PhysHlth),
            min = min(PhysHlth), max = max(PhysHlth))
```
People without diabetes are expected on average to be more physically active. A low average number of days with psychical injury is expected for people without diabetes when compared to people with diabetes.  

Socioeconomic status plays an important role in risk for diabetes. Here we summarized the impact of *Income* on diabetes_status.

```{r}
diabetes_education_level %>% group_by(Diabetes_binary) %>% 
  count(Income)

```
The reader should look for trends on how Income of the respondent plays a role in diabetes_status.  


Here we looked at demographics impact (age and sex) on diabetes_status using a 3-way contingency table.

```{r}
# 3-way contingency table for diabetes status, age and sex
table(diabetes_education_level$Age, diabetes_education_level$Sex,
      diabetes_education_level$Diabetes_binary)
```
The reader should look for differences in male and female diabetes_status and also how age impacts it!!  


### Summary Plots
The full data set was summarized into several plots as part of the EDA.The plots below give key information about trends in data. Using graphics, we looked at how health, socioeconomic status, and demographics affect diabetes_status.  

Here, we created a visual of the correlation among different health indicating variables using the *corrplot* library. 
```{r}
# Correlation of numeric variables.
Correlation <- cor(select(diabetes_education_level, 
                          c("BMI","MentHlth","PhysHlth")))
corrplot(Correlation,  tl.pos = "lt")
```

The reader should look for any strong (positive or negative) correlation among the numeric variables to minimize collinearity.  

Demographics might have a role in risk for diabetes. Here we looked at trends on how age impacts diabetes_status. 

```{r}
# Barplot of respondents age and diabetes status
g1 <- ggplot(data = diabetes_education_level, aes(x = Age)) +
  labs(x = "Age Group", title = "Bar Plot of Age of Respondents in the diabetes study",
       y = "number of respondents") + 
  scale_fill_discrete(name = "Diabetes Status", labels = c("Have diabetes", "Don't have diabetes"))
g1 + geom_bar(aes(fill = Diabetes_binary)) + theme_bw()

```

The reader should look for trends in how proportion of people with diabetes changes with age.  

As part of demographics, we looked at trends in diabetes_status for men and women here.

```{r}
# Barplot of respondents age and diabetes status
g2 <- ggplot(data = diabetes_education_level, aes(x = Sex)) +
  labs(x = "Sex", title = "Bar Plot of Sex of Respondents in the diabetes study",
       y = "number of respondents") + 
  scale_fill_discrete(name = "Diabetes Status", labels = c("Have diabetes", "Don't have diabetes")) +
  scale_x_discrete(labels = c("Female", "Male"))
g2 + geom_bar(aes(fill = Diabetes_binary)) + theme_bw()

```
The reader should look for trends in how diabetes_status changes for men and women. 



# Scatter plot of 
g2 <- 
## Modeling

### Splitting Train and Test data sets

```{r}
set.seed(12345)
train <- sample(1:nrow(diabetes_education_level), size = nrow(diabetes_education_level)*0.7) # 70/30 split
test <- dplyr::setdiff(1:nrow(diabetes_education_level), train)
diabetes_train <- diabetes_education_level[train,]
daibetes_test <- diabetes_education_level[test,]
```

### Log-loss

Log-loss, also known as cross-entropy loss or logistic loss, is a commonly used metric in machine learning and specifically in classification problems. It measures the performance of a classification model whose output is a probability value between 0 and 1.

Log-loss is a more informative metric than accuracy for several reasons:

- It penalizes models for being confident in their wrong predictions. Accuracy simply counts the number of correct predictions, but it does not consider how confident the model was in those predictions. A model that is confident in its wrong predictions is more likely to make mistakes in the future. Log-loss penalizes models for being confident in their wrong predictions, which encourages them to be more cautious.

- It is robust to imbalanced datasets. When a dataset is imbalanced, one class may be much more common than the other class. This can lead to models that are biased towards predicting the majority class. Accuracy is not robust to imbalanced datasets, as it can be high even if the model is simply predicting the majority class all the time. Log-loss is robust to imbalanced datasets, as it penalizes models for being confident in their wrong predictions, even if they are predicting the majority class.

- It is more sensitive to small changes in model performance. Accuracy is a step function, meaning that it only changes when a model makes a mistake. Log-loss is a continuous function, meaning that it changes even when a model's predictions are slightly off. This makes log-loss a more sensitive metric for evaluating model performance, and it can be used to identify areas where a model can be improved.

In general, log-loss is a better metric than accuracy for evaluating the performance of machine learning models, particularly for classification problems. It is more informative, robust to imbalanced datasets, and more sensitive to small changes in model performance.


### Logistic Regression

Logistic regression is a statistical model that is used to predict the probability of a binary outcome. Logistic regression models are trained on historical data that includes both the outcome variable and a set of predictor variables. The model then learns to predict the probability of the outcome variable for new data points based on the values of the predictor variables.

Logistic regression models are a type of supervised learning model, which means that they are trained on labeled data. Labeled data is data where each data point has a known outcome value. This allows the model to learn the relationship between the predictor variables and the outcome variable.

We can use logistic regression on this project because the outcome of the dataset, Diabetes_binary, is in binary format.

```{r}

# Model 1: Forward Selection
Model_1_Forward <- train(
  Diabetes_binary ~ .-Education,
  data = diabetes_train,
  method = "glmStepAIC",
  family = "binomial",
  direction = "forward",
  metric = "logLoss",
  trace = FALSE,
  trControl = trainControl(method = "cv", 
                           number = 5,
                           preProcOptions = c("center","scale"),
                           summaryFunction = mnLogLoss,
                           classProbs = TRUE)
  )


# Model 2: Backward Selection
Model_2_Backward <- train(
  Diabetes_binary ~ . -Education,
  data = diabetes_train,
  method = "glmStepAIC",
  family = "binomial",
  direction = "backward",
  metric = "logLoss",
  trace = FALSE,
  trControl = trainControl(method = "cv", 
                           number = 5,
                           preProcOptions = c("center","scale"),
                           summaryFunction = mnLogLoss,
                           classProbs = TRUE)
  )


# Model 3: Full model
Model_3_Full <- train(
  Diabetes_binary ~ . -Education,
  data = diabetes_train,
  method = "glm",
  metric = "logLoss",
  trace = FALSE,
  trControl = trainControl(method = "cv", 
                           number = 5,
                           preProcOptions = c("center","scale"),
                           summaryFunction = mnLogLoss,
                           classProbs = TRUE)
  )

Model_1_Forward
Model_2_Backward
Model_3_Full

```
The Logloss value of Forward selection model is `Model_1_Forward$results$logLoss`, the Logloss value of Backward selection model is `Model_2_Backward$results$logLoss`, and the Logloss value of Full model is `Model_3_Full$results$logLoss`. The second model has the lowest Logloss value, so it is the "best" model in these three.  


### LASSO Logistic Regression Model

```{r}

```


### Classification Tree Model

```{r}

```


### Random Forest Model

A random forest is a machine learning algorithm that uses a collection of decision trees to make predictions. Decision trees are a type of supervised learning algorithm that can be used for classification and regression tasks. They work by building a tree-like structure that splits the data into different branches based on the values of the features. The leaves of the tree represent the predictions.

Random forests differ from decision trees in two main ways:

 - Random forests use multiple decision trees. This is called ensemble learning. By averaging the predictions of multiple decision trees, random forests can reduce the risk of overfitting and improve the overall accuracy of the model.
 
 - Random forests use a random subset of features to build each decision tree. This is called feature bagging. Feature bagging helps to reduce the correlation between the decision trees, which further improves the accuracy of the model.

```{r}

# Random Forest Model
Model_rf <- train(
  Diabetes_binary ~ . -Education,
  data = diabetes_train,
  method = "rf",
  metric = "logLoss",
  trControl = trainControl(method = "cv", 
                           number = 5,
                           preProcOptions = c("center","scale"),
                           summaryFunction = mnLogLoss,
                           classProbs = TRUE),
  tuneGrid = data.frame(mtry = seq(1:10))
  )

```


### Partial Least Squares Model

Partial Least Squares (PLS) is a statistical method that is often used in regression and classification analysis. PLS regression is commonly employed when there are high collinearity among the predictor variables, and it aims to find the directions (latent variables or components) that explain both the variance in the predictor variables and the variance in the response variable.

Partial Least Squares Discriminant Analysis (PLS-DA) is an extension of PLS that is specifically used for classification purposes. PLS-DA combines elements of principal component analysis (PCA) and canonical correlation analysis to find the linear combinations of the original variables (features) that best discriminate between different classes in the response variable.

In the context of classification, the goal of PLS-DA is to find a set of latent variables (components) that maximize the separation between different classes while also explaining the variance in the predictor variables. These latent variables are then used to build a predictive model for classifying new observations into predefined classes.

PLS and PLS-DA are commonly used in fields such as chemometrics, biology, and other areas where there are complex relationships between variables and a need for effective classification or regression models. They are particularly useful when dealing with high-dimensional data or when there are multicollinearity issues among the predictor variables.

```{r}

# Partial Least Squares Model
Model_pls <- train(
  Diabetes_binary ~ . -Education,
  data = diabetes_train,
  method = "pls",
  metric = "logLoss",
  trControl = trainControl(method = "cv", 
                           number = 5,
                           preProcOptions = c("center","scale"),
                           summaryFunction = mnLogLoss,
                           classProbs = TRUE),
  tuneGrid = data.frame(ncomp = seq(1:15))
  )

```


### Another Model

```{r}

```


## Final Model Selection

```{r}

```

